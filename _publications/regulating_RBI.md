---
title: "Regulating AI-Based Remote Biometric Identification. Investigating the Public Demand for Bans, Audits, and Public Database Registrations"
collection: publications
category: manuscripts
permalink: /publication/regulating_RBI
excerpt: ''
date: 2024-06-05
venue: 'Proceedings of the 2024 ACM Conference on Fairness, Accountability, and Transparency'
#slidesurl: 'https://academicpages.github.io/files/slides1.pdf'
paperurl: 'https://dl.acm.org/doi/abs/10.1145/3630106.3658548'
#bibtexurl: 'https://academicpages.github.io/files/bibtex1.bib'
citation: 'Kieslich, K., & Lünich, M. (2024). Regulating AI-Based Remote Biometric Identification. Investigating the Public Demand for Bans, Audits, and Public Database Registrations. Conference Proceeding of the ACM conference on Fairness, Accountability, and Transparency (ACM FAccT). https://doi.org/10.1145/3630106.3658548'
---
AI is increasingly being used in the public sector, including public security. In this context, the use of AI-powered remote biometric identification (RBI) systems is a much-discussed technology. RBI systems are used to identify criminal activity in public spaces, but at the same time they are criticised for inheriting biases and violating fundamental human rights. As a result, the use of RBI poses risks to society. It is therefore important to ensure that such systems are developed in the public interest, which means that any technology that is deployed for public use needs to be scrutinised. While there is a broad consensus among business leaders, policymakers and scientists that AI must be developed in an ethical and trustworthy manner, scholars have argued that ethical guidelines do not guarantee ethical AI, but rather prevent stronger regulation of AI for the Common Good. As a possible counterweight, public opinion can have a decisive influence on policymakers (e.g. through voter demands) to establish boundaries and conditions under which AI systems should be used – if at all. However, we know little about the conditions that lead to regulatory demand for AI systems. In this study, we focus on the role of trust in AI as well as trust in law enforcement as potential factors that may lead to demands for regulation of AI technology. In addition, we explore the mediating effects of discrimination perceptions regarding RBI. We test the effects on four different use cases of RBI varying the temporal aspect (real-time vs. post hoc analysis) and purpose of use (persecution of criminals vs. safeguarding public events) in a survey among German citizens. We found that German citizens do not differentiate between the different modes of application in terms of their demand for RBI regulation. Furthermore, we show that perceptions of discrimination lead to a demand for stronger regulation, while trust in AI and trust in law enforcement lead to opposite effects in terms of demand for a ban on RBI systems.
